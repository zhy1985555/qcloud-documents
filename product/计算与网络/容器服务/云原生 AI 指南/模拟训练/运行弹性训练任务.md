## 概述 

传统分布式深度学习任务（例如 Tensorflow Job）在提交训练任务后，无法再动态调整 Worker 数量。但在某些场景下，需要弹性训练能力，例如，集群中存在一批算力需求波动大的高优任务（例如周期性波动的在线任务)，集群的整体平均资源利用率较低，因为波谷期的资源未得到充分利用。这种场景下，可以在集群中运行弹性训练任务，充分利用集群闲置资源。

MPI Operator 通过对接 Horovod 的 Elastic 模式，可以让 MPI Job 具备**动态调整训练 Workers 数量**的能力。您可以结合云原生的**低成本算力能力（竞价实例）以及多维度弹性能力**（例如 HPA、VPA、CA）充分利用空闲的算力资源，以大幅降低训练成本。本文介绍如何运行 MPI 任务。

## 前提条件

- AI 环境中已安装 [MPI Operator](https://cloud.tencent.com/document/product/457/62634)。
- AI 环境中有 GPU 资源。


## 操作步骤

`MPI-Operator` 官方提供了多个训练案例，本文将以 Horovod Elastic 训练为例。


### 准备训练代码

本示例中使用 Horovod 官方提供的示例代码 [tensorflow2_mnist_elastic.py](https://github.com/horovod/horovod/blob/v0.20.0/examples/elastic/tensorflow2_mnist_elastic.py)。


### 制作训练镜像

Horovod 官方提供的 `horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu` 镜像中已经包含了该训练代码。

> ! 
> - 如果采用其他 Horovod 镜像作为基础镜像来制作训练镜像，请将训练代码复制至到镜像内。
> - 由于训练代码是基于 TensorFlow 2.3.0 构建，如果采用不同的 TensorFlow 版本，请注意 API 兼容性。



#### 腾讯云自研优化镜像

> ? 镜像仓库 `ccr.ccs.tencentyun.com/ti_containers/ti-tensorflow` 中内置了由**腾讯优图实验室和机智团队**合作开发的 Ti-horovod，针对腾讯云网络环境特点进行了**定制优化**。


**标签（tag）列表**
- `1.15.2-gpu-cu100-py3`
- `2.0.0-gpu-cu100-py3`
- `2.1.0-gpu-cu101-py3`
- `2.4.0-gpu-cu112-py3`
- `2.4.0-gpu-cu113-py3`

### 任务提交

1. 准备一个 MPIJob 的 [YAML 文件](https://raw.githubusercontent.com/kubeflow/mpi-operator/master/examples/horovod/tensorflow-mnist-elastic.yaml)，定义一个 Horovod Elastic 任务，至少需要1个 Worker，至多接受3个 Worker，最初创建2个 Worker。
```yaml
apiVersion: kubeflow.org/v1
kind: MPIJob
metadata:
  name: tensorflow-mnist-elastic
spec:
  slotsPerWorker: 1
  cleanPodPolicy: Running
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          containers:
          - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
            name: mpi-launcher
            command:
            - horovodrun
            args:
            - -np
            - "2"
            - --min-np
            - "1"
            - --max-np
            - "3"
            - --host-discovery-script
            - /etc/mpi/discover_hosts.sh
            - python
            - /examples/elastic/tensorflow2_mnist_elastic.py
            resources:
              limits:
                cpu: 1
                memory: 2Gi
    Worker:
      replicas: 2
      template:
        spec:
          containers:
          - image: horovod/horovod:0.20.0-tf2.3.0-torch1.6.0-mxnet1.5.0-py3.7-cpu
            name: mpi-worker
            resources:
              limits:
                cpu: 2
                memory: 4Gi
```
2. 执行以下命令，通过 `kubectl` 提交该 MPIJob：
```shell
kubectl create -f ./tensorflow-mnist-elastic.yaml
```
3. 如需修改 Worker 数量，可以通过 `kubectl edit` 或 `kubectl patch` 来修改该 MPIJob 的 `spec.mpiReplicaSpecs[Worker].replicas`。
